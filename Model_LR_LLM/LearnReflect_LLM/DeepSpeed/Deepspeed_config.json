{
    "train_batch_size": 4, 
    "train_micro_batch_size_per_gpu": 2,
    "gradient_accumulation_steps": 4,
    "world_size": 2, 
    "steps_per_print": 10,
    "bf16": {
        "enabled": true  
    },
    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu"
        },
        "offload_param": {
            "device": "cpu"
        },
        "contiguous_gradients": true,
        "overlap_comm": true,
        "reduce_scatter": true,
        "allgather_bucket_size": 500000000,
        "allgather_partitions": true,
        "prefetch_bucket_size": 50000000,
        "sub_group_size": 1000000
    },    
    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": 1e-3,  
            "weight_decay": 1e-4,
            "betas": [0.9, 0.999],
            "eps": 1e-8
        }
    },
    "scheduler": {
        "type": "WarmupDecayLR",
        "params": {
            "warmup_min_lr": 0.0,
            "warmup_max_lr": 0.001,
            "warmup_num_steps": 100,
            "total_num_steps": 1000
        }
    },
    "gradient_clipping": 0.5,
    "tensorboard": {
        "enabled": true,
        "output_path": "/mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/LR_AI_LLM Model/LearnReflect_Language_Model_ChatbotAI/LR_AI_LLM/Logs",
        "job_name": "Two_GPU_Training"
    },
    "moe": {
        "enabled": true,
        "num_experts": 8, 
        "num_experts_per_gpu": 8,  
        "top_k": 2,  
        "loss_coef": 0.01
    }
}
